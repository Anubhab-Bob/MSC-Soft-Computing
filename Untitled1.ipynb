{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adverse-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Custom Perceptron\n",
    "from perceptron import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "nervous-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "detailed-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 bit binary data for 3 i/p NOR gate\n",
    "X = np.array([ \n",
    "    [-1, -1, -1], \n",
    "    [-1, -1, 1], \n",
    "    [-1, 1, -1], \n",
    "    [-1, 1, 1], \n",
    "    [1, -1, -1], \n",
    "    [1, -1, 1], \n",
    "    [1, 1, -1], \n",
    "    [1, 1, 1] \n",
    "])\n",
    "y = np.array(\n",
    "    [1, -1, -1, -1, -1, -1, -1, -1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "destroyed-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dried-classification",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "either both or neither of x and y should be given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0fc62fbb96dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Python\\Soft Computing\\perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mido\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mlinear_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0my_predicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;31m# Calculate updated values of weights and bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Python\\Soft Computing\\perceptron.py\u001b[0m in \u001b[0;36m_unit_step_func\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Defining Activation Function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_unit_step_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         return np.array((np.where(x>self.threshold, 1),\n\u001b[0m\u001b[0;32m     43\u001b[0m                          (np.where(x<self.threshold, -1), 0), 0))\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: either both or neither of x and y should be given"
     ]
    }
   ],
   "source": [
    "p = Perceptron(learning_rate=0.5, epochs=1000)\n",
    "p.fit(X_train, y_train)\n",
    "predictions = p.predict(X_test)\n",
    "obj = zip(X_train, y_train)\n",
    "print(list(obj))\n",
    "print(\"Perceptron classification Accuracy : \",accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fiscal-answer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plt.scatter(X_train[:,0], X_train[:,1], marker='o',c=y_train)\n",
    "\n",
    "x0_1 = np.amin(X_train[:,0])\n",
    "x0_2 = np.amax(X_train[:,0])\n",
    "\n",
    "x1_1 = (-p.weights[0] * x0_1 - p.bias) / p.weights[1]\n",
    "x1_2 = (-p.weights[0] * x0_2 - p.bias) / p.weights[1]\n",
    "\n",
    "ax.plot([x0_1, x0_2],[x1_1, x1_2], 'k')\n",
    "\n",
    "ymin = np.amin(X_train[:,1])\n",
    "ymax = np.amax(X_train[:,1])\n",
    "ax.set_ylim([ymin-3,ymax+3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "roman-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\t-1\t-1\t1\n",
      "-1\t-1\t1\t-1\n",
      "-1\t1\t-1\t-1\n",
      "-1\t1\t1\t-1\n",
      "1\t-1\t-1\t-1\n",
      "1\t-1\t1\t-1\n",
      "1\t1\t-1\t-1\n",
      "1\t1\t1\t-1\n"
     ]
    }
   ],
   "source": [
    "toPrint = [\"{1}\\t{2}\\t{3}\\t{0}\".format(output, *datas)   \n",
    "              for datas, output in zip(X, y)] \n",
    "for i in toPrint: \n",
    "    print(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-relaxation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
