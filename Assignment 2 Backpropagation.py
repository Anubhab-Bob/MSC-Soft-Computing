#!/usr/bin/env python
# coding: utf-8

# ## Write a python script to train a 4-3-3-2 feed forward neural network using back propagation
# The following code generates a 4 layer feed forward neural network using back propagation method.
# The number of neurons in each layer can be given at runtime along with the learning rate. The code
# also shows the accuracy of the model computed using built-in functions from the numpy package

# In[82]:


# import necessary libraries
import numpy as np
from math import exp

# Define necessary constants
MAX_EPOCH = 50000


# In[83]:


# Function to generate inputs to the non-input layers
def hidin(n_neurons_hi, n_neurons_prev, input_weights, input_values, h_bias):
    ind=0
    hid_net = []
    for i in range(n_neurons_hi):
        temp_in=0
        j=0
        while(j<n_neurons_prev):
            temp_in += (input_weights[ind]*input_values[j])
            j += 1
            ind += 1
        temp_in += h_bias[i]
        hid_net.append(temp_in)
    return hid_net


# In[15]:


# Function to generate outputs of the non-input layers
def hidout(hid_net):
    hid_out = []
    for i in hid_net:
        x=1/(1+exp(-i))  # sigmoid function used as activation function
        hid_out.append(x)
    return hid_out


# In[84]:


# Function to calculate the error generated by output layer
def output_err(n_neurons, out, label):
    flag = True
    error = []
    #ERROR IN OUTPUT LAYER
    for i in range(n_neurons):
        err_i=out[i]*(1-out[i])*(label[i]-out[i])
        error.append(err_i)
    #####
    cn=0
    for i in error:
        if(i < 0.0001):
            cn += 1
    if(cn == len(out)):
        flag = False
    return flag, error


# In[85]:


# Function to calculate the error generated by a hidden layer
def hidden_err(n_neurons, hid_out, error_out, output_weights):
    #ERROR IN HIDDEN LAYER
    inr = 0
    error = []
    for i in range(n_neurons):
        x = hid_out[i]*(1-hid_out[i])
        t = 0
        ind = inr
        for j in error_out:
            t += j * output_weights[ind]
            ind += n_neurons
        x = x * t
        error.append(x)
        inr += 1
    return error


# In[37]:


# Function to update weights and biases depending on the outputs of the layers
def update(n_in, in_val, n_hid1, n_hid2, n_out, h1_weights, h2_weights,
           out_weights, h1_bias, h2_bias, out_bias, hid_out1, hid_out2,
           out_out, hid_err1, hid_err2, out_error, l):
    temp_wei=[]
    ind=0
    # Update Weights of 1st Hidden Layer
    for i in range(n_hid1):
        j=0
        while j<n_in:
            x=h1_weights[ind]
            x += (l*hid_err1[i]*in_val[j])
            j += 1
            ind += 1
            temp_wei.append(x)
    h1_weights.clear()
    h1_weights = temp_wei.copy()
    temp_wei.clear()
    # Update Weights of 2nd Hidden Layer
    ind=0
    for i in range(n_hid2):
        j=0
        while j<n_hid1:
            x = h2_weights[ind]
            x += (l*hid_err2[i]*hid_out1[j])
            j += 1
            ind += 1
            temp_wei.append(x)
    h2_weights.clear()
    h2_weights = temp_wei.copy()
    temp_wei.clear()
    # Update Weights of the output layer
    ind=0
    for i in range(0,n_out):
        for j in range(0,n_hid2):
            x = out_weights[ind]
            x += (l*out_error[i]*hid_out2[j])
            temp_wei.append(x)
            ind += 1
    out_weights.clear()
    out_weights=temp_wei.copy()
    temp_wei.clear()
    # Update biases of 1st Hidden layer
    for i in range(0,n_hid1):
        x = h1_bias[i]+(l*hid_err1[i])
        temp_wei.append(x)
    h1_bias.clear()
    h1_bias=temp_wei.copy()
    temp_wei.clear()
    # Update biases of 2nd Hidden layer
    for i in range(0,n_hid2):
        x = h2_bias[i]+(l*hid_err2[i])
        temp_wei.append(x)
    h2_bias.clear()
    h2_bias = temp_wei.copy()
    temp_wei.clear()
    # Update biases of output layer
    for i in range(0,n_out):
        x=out_bias[i]+(l*out_error[i])
        temp_wei.append(x)
    out_bias.clear()
    out_bias = temp_wei.copy()

    return h1_weights, h2_weights, out_weights, h1_bias, h2_bias, out_bias


# In[81]:


# Generate the neural network
def neural_network(n_in, n_hid1, n_hid2, n_out):
    input_val = []
    h1_weights = []
    h2_weights = []
    out_weights = []
    h1_bias = []
    h2_bias = []
    out_bias = []
    label = []
    # Inputs to the neural network
    for i in range(n_in):
        print("Input value for neuron ",i+1)
        x=input("Enter: ")
        input_val.append(int(x))

    # Weights of 1st Hidden Layer
    for i in range(0,n_hid1):
        j = 0
        while j<n_in:
            x = round(np.random.rand(),2)
            h1_weights.append(x)
            j += 1
    # Weights of 2nd Hidden layer
    for i in range(0,n_hid2):
        j = 0
        while j<n_hid1:
            x = round(np.random.rand(),2)
            h2_weights.append(x)
            j += 1
    # Weights of Output Layer
    for i in range(0,n_out):
        j = 0
        while j<n_hid2:
            x = round(np.random.rand(),2)
            out_weights.append(x)
            j += 1

    # Biases of 1st Hidden Layer
    for i in range(n_hid1):
        x = round(np.random.rand(),2)
        h1_bias.append(x)
    # Biases of 2nd Hidden Layer
    for i in range(n_hid2):
        x = round(np.random.rand(),2)
        h2_bias.append(x)
    # Biases and labels of output neurons
    for i in range(n_out):
        #print("Bias and class label for output neuron: ",n_in+n_hid+i+1)
        x = round(np.random.rand(),2)
        y = input("Enter class label for output neuron: ")
        out_bias.append(x)
        label.append(int(y))

    return input_val, h1_weights, h2_weights, out_weights, h1_bias, h2_bias, out_bias, label


# In[80]:


n_in = int(input("Enter the number of input neurons >> "))  # number of neurons in input layer
n_hid1 = int(input("Enter the number of neurons in 1st hidden layer >> "))  # number of neurons in 1st hidden layer
n_hid2 = int(input("Enter the number of neurons in 2nd hidden layer >> "))  # number of neurons in 2nd hidden layer
n_out = int(input("Enter the number of output neurons >> "))  # number of neurons in output layer
l = float(input("Enter the learning rate >> "))  # learning rate of the network
# Generate the network
input_val, h1_weights, h2_weights, out_weights, h1_bias, h2_bias, out_bias, label = neural_network(n_in,
                                                                                                  n_hid1,
                                                                                                  n_hid2,
                                                                                                  n_out)
# Display initial weights and biases
print("_______Initial Weights_______")
print(h1_weights)
print(h2_weights)
print(out_weights)
print("_______Initial Bias_______")
print(h1_bias)
print(h2_bias)
print(out_bias)

# Train the network to realise the output from given inputs
for _ in range(MAX_EPOCH):
    hid_net1 = hidin(n_hid1, n_in, h1_weights, input_val, h1_bias)
    hid_out1 = hidout(hid_net1)
    hid_net2 = hidin(n_hid2, n_hid1, h2_weights, hid_out1, h2_bias)
    hid_out2 = hidout(hid_net2)
    out_net = hidin(n_out, n_hid2, out_weights, hid_out2, out_bias)
    out_out = hidout(out_net)
    # Get the error in output
    flag, out_error = output_err(n_out, out_out, label)
    if flag == True:
        # Get error in hidden layers
        hid_error2 = hidden_err(n_hid2, hid_out2, out_error, out_weights)
        hid_error1 = hidden_err(n_hid1, hid_out1, hid_error2, h2_weights)
        # Update the weights and biases of the model
        h1_weights, h2_weights, out_weights, h1_bias, h2_bias, out_bias = update(n_in, input_val, n_hid1, n_hid2,
                                                                                 n_out, h1_weights, h2_weights,
                                                                                 out_weights, h1_bias, h2_bias,
                                                                                 out_bias, hid_out1, hid_out2,
                                                                                 out_out, hid_error1, hid_error2,
                                                                                 out_error, l)
# Display final weights and biases
print("_______Final Weights_______")
print(np.array2string(np.float_(([ '%.2f' % elem for elem in h1_weights ])), separator=', '))
print(np.array2string(np.float_(([ '%.2f' % elem for elem in h2_weights ])), separator=', '))
print(np.array2string(np.float_(([ '%.2f' % elem for elem in out_weights ])), separator=', '))
print("_______Final Bias_______")
print(np.array2string(np.float_(([ '%.2f' % elem for elem in h1_bias ])), separator=', '))
print(np.array2string(np.float_(([ '%.2f' % elem for elem in h2_bias ])), separator=', '))
print(np.array2string(np.float_(([ '%.2f' % elem for elem in out_bias ])), separator=', '))

#Display the true and generated outputs
print("Expected Output: ")
label = np.array(label)
print(label)
print("Actual Output:" )
out_out = np.array(out_out)
print(out_out)
error = [abs(i) for i in label-out_out]  # Calculate the final error
accuracy = np.mean([1-i for i in error]) * 100  # Calculate the accuracy %
print("Accuracy:\n%4.2f"%accuracy+"%")


# In[ ]:




