{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "japanese-liability",
   "metadata": {},
   "source": [
    "## Write a python script to train a 4-3-3-2 feed forward neural network using back propagation\n",
    "The following code generates a 4 layer feed forward neural network using back propagation method. The number of neurons in each layer can be given at runtime along with the learning rate. The code also shows the accuracy of the model computed using built-in functions from the numpy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "conscious-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "# Define necessary constants\n",
    "MAX_EPOCH = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "stable-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate inputs to the non-input layers\n",
    "def hidin(n_neurons_hi, n_neurons_prev, input_weights, input_values, h_bias):\n",
    "    ind=0\n",
    "    hid_net = [] \n",
    "    for i in range(n_neurons_hi):\n",
    "        temp_in=0\n",
    "        j=0\n",
    "        while(j<n_neurons_prev):\n",
    "            temp_in += (input_weights[ind]*input_values[j])\n",
    "            j += 1\n",
    "            ind += 1\n",
    "        temp_in += h_bias[i]\n",
    "        hid_net.append(temp_in)\n",
    "    return hid_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rotary-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate outputs of the non-input layers\n",
    "def hidout(hid_net):\n",
    "    hid_out = []\n",
    "    for i in hid_net:\n",
    "        x=1/(1+exp(-i))  # sigmoid function used as activation function\n",
    "        hid_out.append(x)\n",
    "    return hid_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "comparative-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the error generated by output layer\n",
    "def output_err(n_neurons, out, label):\n",
    "    flag = True\n",
    "    error = []\n",
    "    #ERROR IN OUTPUT LAYER\n",
    "    for i in range(n_neurons):\n",
    "        err_i=out[i]*(1-out[i])*(label[i]-out[i])\n",
    "        error.append(err_i)\n",
    "    #####\n",
    "    cn=0\n",
    "    for i in error:\n",
    "        if(i < 0.0001):\n",
    "            cn += 1\n",
    "    if(cn == len(out)):\n",
    "        flag = False\n",
    "    return flag, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "alpha-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the error generated by a hidden layer\n",
    "def hidden_err(n_neurons, hid_out, error_out, output_weights):\n",
    "    #ERROR IN HIDDEN LAYER\n",
    "    inr = 0\n",
    "    error = []\n",
    "    for i in range(n_neurons):\n",
    "        x = hid_out[i]*(1-hid_out[i])\n",
    "        t = 0\n",
    "        ind = inr\n",
    "        for j in error_out:\n",
    "            t += j * output_weights[ind]\n",
    "            ind += n_neurons\n",
    "        x = x * t\n",
    "        error.append(x)\n",
    "        inr += 1\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "documented-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update weights and biases depending on the outputs of the layers\n",
    "def update(n_in, in_val, n_hid1, n_hid2, n_out, h1_weights, h2_weights,\\\n",
    "           out_weights, h1_bias, h2_bias, out_bias, hid_out1, hid_out2,\\\n",
    "           out_out, hid_err1, hid_err2, out_error, l):\n",
    "    temp_wei=[]\n",
    "    ind=0   \n",
    "    # Update Weights of 1st Hidden Layer\n",
    "    for i in range(n_hid1):\n",
    "        j=0\n",
    "        while j<n_in:\n",
    "            x=h1_weights[ind]\n",
    "            x += (l*hid_err1[i]*in_val[j])\n",
    "            j += 1\n",
    "            ind += 1\n",
    "            temp_wei.append(x)\n",
    "    h1_weights.clear()\n",
    "    h1_weights = temp_wei.copy()\n",
    "    temp_wei.clear()\n",
    "    # Update Weights of 2nd Hidden Layer\n",
    "    ind=0    \n",
    "    for i in range(n_hid2):\n",
    "        j=0\n",
    "        while j<n_hid1:\n",
    "            x = h2_weights[ind]\n",
    "            x += (l*hid_err2[i]*hid_out1[j])\n",
    "            j += 1\n",
    "            ind += 1\n",
    "            temp_wei.append(x)\n",
    "    h2_weights.clear()\n",
    "    h2_weights = temp_wei.copy()\n",
    "    temp_wei.clear()\n",
    "    # Update Weights of the output layer\n",
    "    ind=0\n",
    "    for i in range(0,n_out):\n",
    "        for j in range(0,n_hid2):\n",
    "            x = out_weights[ind]\n",
    "            x += (l*out_error[i]*hid_out2[j])\n",
    "            temp_wei.append(x)\n",
    "            ind += 1\n",
    "    out_weights.clear()\n",
    "    out_weights=temp_wei.copy()\n",
    "    temp_wei.clear()\n",
    "    # Update biases of 1st Hidden layer\n",
    "    for i in range(0,n_hid1):\n",
    "        x = h1_bias[i]+(l*hid_err1[i])\n",
    "        temp_wei.append(x)\n",
    "    h1_bias.clear()\n",
    "    h1_bias=temp_wei.copy()\n",
    "    temp_wei.clear()\n",
    "    # Update biases of 2nd Hidden layer\n",
    "    for i in range(0,n_hid2):\n",
    "        x = h2_bias[i]+(l*hid_err2[i])\n",
    "        temp_wei.append(x)\n",
    "    h2_bias.clear()\n",
    "    h2_bias = temp_wei.copy()\n",
    "    temp_wei.clear()\n",
    "    # Update biases of output layer\n",
    "    for i in range(0,n_out):\n",
    "        x=out_bias[i]+(l*out_error[i])\n",
    "        temp_wei.append(x)\n",
    "    out_bias.clear()\n",
    "    out_bias = temp_wei.copy()\n",
    "    \n",
    "    return h1_weights, h2_weights, out_weights, h1_bias, h2_bias, out_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "prescribed-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the neural network\n",
    "def neural_network(n_in, n_hid1, n_hid2, n_out):\n",
    "    input_val = []\n",
    "    h1_weights = []\n",
    "    h2_weights = []\n",
    "    out_weights = []\n",
    "    h1_bias = []\n",
    "    h2_bias = []\n",
    "    out_bias = []\n",
    "    label = []\n",
    "    # Inputs to the neural network\n",
    "    for i in range(n_in):\n",
    "        print(\"Input value for neuron \",i+1)\n",
    "        x=input(\"Enter: \")\n",
    "        input_val.append(int(x))\n",
    "        \n",
    "    # Weights of 1st Hidden Layer\n",
    "    for i in range(0,n_hid1):\n",
    "        j = 0\n",
    "        while j<n_in:\n",
    "            x = round(np.random.rand(),2)\n",
    "            h1_weights.append(x)\n",
    "            j += 1\n",
    "    # Weights of 2nd Hidden layer\n",
    "    for i in range(0,n_hid2):\n",
    "        j = 0\n",
    "        while j<n_hid1:\n",
    "            x = round(np.random.rand(),2)\n",
    "            h2_weights.append(x)\n",
    "            j += 1\n",
    "    # Weights of Output Layer\n",
    "    for i in range(0,n_out):\n",
    "        j = 0\n",
    "        while j<n_hid2:\n",
    "            x = round(np.random.rand(),2)\n",
    "            out_weights.append(x)\n",
    "            j += 1\n",
    "            \n",
    "    # Biases of 1st Hidden Layer\n",
    "    for i in range(n_hid1):\n",
    "        x = round(np.random.rand(),2)\n",
    "        h1_bias.append(x)\n",
    "    # Biases of 2nd Hidden Layer\n",
    "    for i in range(n_hid2):\n",
    "        x = round(np.random.rand(),2)\n",
    "        h2_bias.append(x)\n",
    "    # Biases and labels of output neurons    \n",
    "    for i in range(n_out):\n",
    "        #print(\"Bias and class label for output neuron: \",n_in+n_hid+i+1)\n",
    "        x = round(np.random.rand(),2)\n",
    "        y = input(\"Enter class label for output neuron: \")\n",
    "        out_bias.append(x)\n",
    "        label.append(int(y))\n",
    "\n",
    "    return input_val, h1_weights, h2_weights, out_weights, h1_bias, h2_bias, out_bias, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "russian-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of input neurons >> 4\n",
      "Enter the number of neurons in 1st hidden layer >> 3\n",
      "Enter the number of neurons in 2nd hidden layer >> 3\n",
      "Enter the number of output neurons >> 2\n",
      "Enter the learning rate >> 1\n",
      "Input value for neuron  1\n",
      "Enter: 0\n",
      "Input value for neuron  2\n",
      "Enter: 1\n",
      "Input value for neuron  3\n",
      "Enter: 0\n",
      "Input value for neuron  4\n",
      "Enter: 1\n",
      "Enter class label for output neuron: 1\n",
      "Enter class label for output neuron: 0\n",
      "_______Initial Weights_______\n",
      "[0.06, 0.52, 0.25, 0.04, 0.83, 0.03, 0.35, 0.26, 0.06, 0.65, 0.16, 0.3]\n",
      "[0.64, 0.8, 0.94, 0.7, 0.44, 0.97, 0.75, 0.67, 0.47]\n",
      "[0.29, 0.87, 0.53, 0.59, 0.11, 0.85]\n",
      "_______Initial Bias_______\n",
      "[0.16, 0.43, 0.37]\n",
      "[0.73, 0.76, 0.52]\n",
      "[0.92, 0.62]\n",
      "_______Final Weights_______\n",
      "[0.06, 0.56, 0.25, 0.08, 0.83, 0.06, 0.35, 0.29, 0.06, 0.69, 0.16, 0.34]\n",
      "[0.68, 0.84, 0.99, 0.8 , 0.54, 1.09, 0.78, 0.7 , 0.5 ]\n",
      "[ 0.85,  1.43,  1.05, -1.16, -1.63, -0.78]\n",
      "_______Final Bias_______\n",
      "[0.2 , 0.46, 0.41]\n",
      "[0.79, 0.91, 0.56]\n",
      "[ 1.53, -1.28]\n",
      "Expected Output: \n",
      "[1 0]\n",
      "Actual Output:\n",
      "[0.98995295 0.01018132]\n",
      "Accuracy:\n",
      "98.99%\n"
     ]
    }
   ],
   "source": [
    "n_in = int(input(\"Enter the number of input neurons >> \"))  # number of neurons in input layer\n",
    "n_hid1 = int(input(\"Enter the number of neurons in 1st hidden layer >> \"))  # number of neurons in 1st hidden layer\n",
    "n_hid2 = int(input(\"Enter the number of neurons in 2nd hidden layer >> \"))  # number of neurons in 2nd hidden layer\n",
    "n_out = int(input(\"Enter the number of output neurons >> \"))  # number of neurons in output layer\n",
    "l = float(input(\"Enter the learning rate >> \"))  # learning rate of the network\n",
    "# Generate the network\n",
    "input_val, h1_weights, h2_weights, out_weights, h1_bias, h2_bias, out_bias, label = neural_network(\\\n",
    "                                                                                                  n_in,\n",
    "                                                                                                  n_hid1,\n",
    "                                                                                                  n_hid2,\n",
    "                                                                                                  n_out)\n",
    "# Display initial weights and biases\n",
    "print(\"_______Initial Weights_______\")\n",
    "print(h1_weights)\n",
    "print(h2_weights)\n",
    "print(out_weights)\n",
    "print(\"_______Initial Bias_______\")\n",
    "print(h1_bias)\n",
    "print(h2_bias)\n",
    "print(out_bias)\n",
    "\n",
    "# Train the network to realise the output from given inputs\n",
    "for _ in range(MAX_EPOCH):\n",
    "    hid_net1 = hidin(n_hid1, n_in, h1_weights, input_val, h1_bias)\n",
    "    hid_out1 = hidout(hid_net1)\n",
    "    hid_net2 = hidin(n_hid2, n_hid1, h2_weights, hid_out1, h2_bias)\n",
    "    hid_out2 = hidout(hid_net2)\n",
    "    out_net = hidin(n_out, n_hid2, out_weights, hid_out2, out_bias)\n",
    "    out_out = hidout(out_net)\n",
    "    # Get the error in output\n",
    "    flag, out_error = output_err(n_out, out_out, label)\n",
    "    if flag == True:\n",
    "        # Get error in hidden layers\n",
    "        hid_error2 = hidden_err(n_hid2, hid_out2, out_error, out_weights)\n",
    "        hid_error1 = hidden_err(n_hid1, hid_out1, hid_error2, h2_weights)\n",
    "        # Update the weights and biases of the model\n",
    "        h1_weights, h2_weights, out_weights, h1_bias, h2_bias, out_bias = update(n_in, input_val,\\\n",
    "                                                                                 n_hid1, n_hid2,\\\n",
    "                                                                                 n_out, h1_weights,\\\n",
    "                                                                                 h2_weights,out_weights,\\\n",
    "                                                                                 h1_bias, h2_bias,\\\n",
    "                                                                                 out_bias, hid_out1,\\\n",
    "                                                                                 hid_out2, out_out,\\\n",
    "                                                                                 hid_error1, hid_error2,\\\n",
    "                                                                                 out_error, l)\n",
    "# Display final weights and biases\n",
    "print(\"_______Final Weights_______\")\n",
    "print(np.array2string(np.float_(([ '%.2f' % elem for elem in h1_weights ])), separator=', '))\n",
    "print(np.array2string(np.float_(([ '%.2f' % elem for elem in h2_weights ])), separator=', '))\n",
    "print(np.array2string(np.float_(([ '%.2f' % elem for elem in out_weights ])), separator=', '))\n",
    "print(\"_______Final Bias_______\")\n",
    "print(np.array2string(np.float_(([ '%.2f' % elem for elem in h1_bias ])), separator=', '))\n",
    "print(np.array2string(np.float_(([ '%.2f' % elem for elem in h2_bias ])), separator=', '))\n",
    "print(np.array2string(np.float_(([ '%.2f' % elem for elem in out_bias ])), separator=', '))\n",
    "\n",
    "#Display the true and generated outputs\n",
    "print(\"Expected Output: \")\n",
    "label = np.array(label)\n",
    "print(label)\n",
    "print(\"Actual Output:\" )\n",
    "out_out = np.array(out_out)\n",
    "print(out_out)\n",
    "error = [abs(i) for i in label-out_out]  # Calculate the final error\n",
    "accuracy = np.mean([1-i for i in error]) * 100  # Calculate the accuracy %\n",
    "print(\"Accuracy:\\n%4.2f\"%accuracy+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-screen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
